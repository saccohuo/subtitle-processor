from flask import Flask, request, jsonify
import os
import logging
import sys
import time
import soundfile as sf
import numpy as np
from funasr import AutoModel
import torch
import json
from pydub import AudioSegment
import tempfile
from modelscope import snapshot_download
from pathlib import Path
import shutil
from datetime import datetime
import difflib
import re

class HotwordPostProcessor:
    """çƒ­è¯åå¤„ç†å™¨ - åœ¨è½¬å½•å®Œæˆåè¿›è¡Œçƒ­è¯åŒ¹é…å’Œæ›¿æ¢"""
    
    def __init__(self):
        self.similarity_threshold = 0.5  # é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œæ›´å®¹æ˜“åŒ¹é…
        self.weight_boost = 1.5  # çƒ­è¯æƒé‡æå‡
        
    def process_text_with_hotwords(self, text, hotwords, confidence_boost=0.1):
        """
        ä½¿ç”¨çƒ­è¯å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œåå¤„ç†
        
        Args:
            text: åŸå§‹è½¬å½•æ–‡æœ¬
            hotwords: çƒ­è¯åˆ—è¡¨
            confidence_boost: ç½®ä¿¡åº¦æå‡å€¼
            
        Returns:
            dict: å¤„ç†åçš„ç»“æœï¼ŒåŒ…å«ä¿®æ­£æ–‡æœ¬å’ŒåŒ¹é…ä¿¡æ¯
        """
        if not text or not hotwords:
            return {
                'original_text': text,
                'processed_text': text,
                'matches': [],
                'corrections': 0
            }
        
        logger.warning(f"ğŸ”¥ å¼€å§‹çƒ­è¯åå¤„ç†ï¼ŒåŸæ–‡æœ¬: '{text}'")
        logger.warning(f"ğŸ”¥ ä½¿ç”¨çƒ­è¯ ({len(hotwords)}ä¸ª): {hotwords}")
        
        # å°†æ–‡æœ¬åˆ†è¯
        words = self._segment_text(text)
        processed_words = []
        matches = []
        corrections = 0
        
        for i, word in enumerate(words):
            # å¯»æ‰¾æœ€åŒ¹é…çš„çƒ­è¯
            best_match = self._find_best_hotword_match(word, hotwords)
            
            if best_match:
                hotword, similarity = best_match
                if similarity >= self.similarity_threshold:
                    logger.warning(f"ğŸ”¥ çƒ­è¯åŒ¹é…: '{word}' -> '{hotword}' (ç›¸ä¼¼åº¦: {similarity:.3f})")
                    processed_words.append(hotword)
                    matches.append({
                        'original': word,
                        'hotword': hotword,
                        'similarity': similarity,
                        'position': i
                    })
                    corrections += 1
                else:
                    processed_words.append(word)
            else:
                processed_words.append(word)
        
        processed_text = ''.join(processed_words)
        
        # æ‰§è¡ŒåŸºäºä¸Šä¸‹æ–‡çš„çƒ­è¯æ›¿æ¢
        processed_text = self._context_based_replacement(processed_text, hotwords)
        
        result = {
            'original_text': text,
            'processed_text': processed_text,
            'matches': matches,
            'corrections': corrections,
            'hotwords_applied': len(hotwords)
        }
        
        logger.warning(f"ğŸ”¥ çƒ­è¯åå¤„ç†å®Œæˆï¼Œä¿®æ­£ {corrections} å¤„ï¼Œæœ€ç»ˆæ–‡æœ¬: '{processed_text}'")
        
        return result
    
    def _segment_text(self, text):
        """åˆ†è¯å¤„ç†ï¼Œä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            import jieba
            # ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯
            words = list(jieba.cut(text))
            logger.warning(f"ğŸ”¥ åˆ†è¯ç»“æœ: {words}")
            return words
        except ImportError:
            # å¦‚æœjiebaä¸å¯ç”¨ï¼Œä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼åˆ†è¯
            # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼ŒåŒæ—¶ä¿ç•™ä¸­æ–‡å­—ç¬¦åºåˆ—
            import re
            # åŒ¹é…ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å•è¯ã€æ•°å­—ã€æ ‡ç‚¹ç¬¦å·
            tokens = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+|[^\w\s]|\s+', text)
            # è¿‡æ»¤ç©ºç™½tokens
            tokens = [token for token in tokens if token.strip()]
            logger.warning(f"ğŸ”¥ æ­£åˆ™åˆ†è¯ç»“æœ: {tokens}")
            return tokens
    
    def _find_best_hotword_match(self, word, hotwords):
        """æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„çƒ­è¯"""
        if not word.strip():
            return None
            
        clean_word = re.sub(r'[^\w]', '', word)  # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        if not clean_word:
            return None
        
        best_match = None
        best_similarity = 0
        
        for hotword in hotwords:
            # ç²¾ç¡®åŒ¹é…
            if clean_word == hotword:
                return (hotword, 1.0)
            
            # å­ä¸²åŒ¹é… - ç‰¹åˆ«é€‚ç”¨äºä¸­æ–‡å¤åˆè¯
            if hotword in clean_word or clean_word in hotword:
                # è®¡ç®—å­ä¸²åŒ¹é…çš„ç›¸ä¼¼åº¦
                if len(hotword) <= len(clean_word):
                    substring_similarity = len(hotword) / len(clean_word) * 0.9  # ç»™å­ä¸²åŒ¹é…ç¨ä½æƒé‡
                else:
                    substring_similarity = len(clean_word) / len(hotword) * 0.9
                
                if substring_similarity > best_similarity:
                    best_similarity = substring_similarity
                    best_match = hotword
                    logger.warning(f"ğŸ”¥ å­ä¸²åŒ¹é…: '{clean_word}' <-> '{hotword}' (ç›¸ä¼¼åº¦: {substring_similarity:.3f})")
            
            # æ¨¡ç³ŠåŒ¹é…
            similarity = difflib.SequenceMatcher(None, clean_word.lower(), hotword.lower()).ratio()
            
            # è€ƒè™‘é•¿åº¦å› ç´ 
            length_factor = min(len(clean_word), len(hotword)) / max(len(clean_word), len(hotword))
            adjusted_similarity = similarity * (0.7 + 0.3 * length_factor)
            
            if adjusted_similarity > best_similarity:
                best_similarity = adjusted_similarity
                best_match = hotword
        
        return (best_match, best_similarity) if best_match else None
    
    def _context_based_replacement(self, text, hotwords):
        """åŸºäºä¸Šä¸‹æ–‡çš„çƒ­è¯æ›¿æ¢"""
        # å¯¹äºå¸¸è§çš„è½¬å½•é”™è¯¯æ¨¡å¼è¿›è¡Œæ›¿æ¢
        replacements = self._generate_common_replacements(hotwords)
        
        for pattern, replacement in replacements.items():
            if pattern in text:
                text = text.replace(pattern, replacement)
                logger.warning(f"ğŸ”¥ ä¸Šä¸‹æ–‡æ›¿æ¢: '{pattern}' -> '{replacement}'")
        
        return text
    
    def _generate_common_replacements(self, hotwords):
        """ç”Ÿæˆå¸¸è§çš„æ›¿æ¢æ¨¡å¼"""
        replacements = {}
        
        # ä¸ºæ¯ä¸ªçƒ­è¯ç”Ÿæˆå¯èƒ½çš„é”™è¯¯è¯†åˆ«æ¨¡å¼
        for hotword in hotwords:
            # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
            hotword_lower = hotword.lower()
            
            # é€šç”¨æ¨¡å¼ï¼šå¤„ç†è‹±æ–‡å•è¯çš„éŸ³è¿‘è¯¯è¯†åˆ«
            if hotword == "ultrathink" or hotword == "Ultrathink":
                replacements.update({
                    "ä¹Œæ‰˜": "ultrathink",
                    "é˜¿å°”ç‰¹æ‹‰": "ultrathink", 
                    "å¥¥ç‰¹æ‹‰": "ultrathink",
                    "ultra": "ultrathink",
                    "Ultra": "ultrathink",
                    "ä¹Œå°”ç‰¹æ‹‰": "ultrathink",
                    "å¥¥æ‹‰": "ultrathink"
                })
            elif hotword == "Python":
                replacements.update({
                    "æ´¾æ£®": "Python",
                    "æ´¾æ¡‘": "Python", 
                    "çš®æ¡‘": "Python",
                    "python": "Python"
                })
            elif hotword == "ç¼–ç¨‹":
                replacements.update({
                    "ä¾¿ç¨‹": "ç¼–ç¨‹",
                    "ç¼–æˆ": "ç¼–ç¨‹",
                    "å˜æˆ": "ç¼–ç¨‹"
                })
            elif hotword == "æœºå™¨å­¦ä¹ ":
                replacements.update({
                    "æœºæ¢°å­¦ä¹ ": "æœºå™¨å­¦ä¹ ",
                    "æœºå™¨é›ªæ´—": "æœºå™¨å­¦ä¹ ",
                    "æœºå™¨è¡€æ´—": "æœºå™¨å­¦ä¹ "
                })
            elif hotword == "æ•™ç¨‹":
                replacements.update({
                    "å«ç¨‹": "æ•™ç¨‹",
                    "è¾ƒç¨‹": "æ•™ç¨‹"
                })
            
            # è‡ªåŠ¨ç”ŸæˆéŸ³è¿‘å­—æ›¿æ¢æ¨¡å¼
            # å¯¹äºè‹±æ–‡è¯æ±‡ï¼ŒæŸ¥æ‰¾å¯èƒ½çš„ä¸­æ–‡éŸ³è¯‘é”™è¯¯
            if re.match(r'^[a-zA-Z]+$', hotword):
                # ä¸ºè‹±æ–‡çƒ­è¯ç”Ÿæˆå¸¸è§çš„ä¸­æ–‡éŸ³è¯‘é”™è¯¯æ¨¡å¼
                phonetic_variants = self._generate_phonetic_variants(hotword)
                for variant in phonetic_variants:
                    replacements[variant] = hotword
        
        return replacements
    
    def _generate_phonetic_variants(self, english_word):
        """ä¸ºè‹±æ–‡å•è¯ç”Ÿæˆå¯èƒ½çš„ä¸­æ–‡éŸ³è¯‘å˜ä½“"""
        variants = []
        word_lower = english_word.lower()
        
        # åŸºäºè‹±æ–‡å•è¯çš„éŸ³èŠ‚ç”Ÿæˆä¸­æ–‡éŸ³è¯‘å˜ä½“
        phonetic_map = {
            'ultra': ['ä¹Œå°”ç‰¹æ‹‰', 'å¥¥ç‰¹æ‹‰', 'é˜¿å°”ç‰¹æ‹‰', 'ä¹Œæ‰˜æ‹‰'],
            'think': ['è¾›å…‹', 'æ€å…‹', 'å¬å…‹', 'æ»•å…‹'],
            'python': ['æ´¾æ£®', 'æ´¾æ¡‘', 'çš®æ¡‘'],
            'java': ['åŠ ç“¦', 'ä½³ç“¦', 'å˜‰ç“¦'],
            'docker': ['é“å…‹', 'å¤šå…‹', 'éƒ½å…‹'],
            'kubernetes': ['åº“ä¼¯å†…è’‚æ–¯', 'åº“è´å†…è’‚æ–¯'],
            'react': ['ç‘è‰¾å…‹ç‰¹', 'é‡Œè‰¾å…‹ç‰¹'],
            'angular': ['å®‰å¤æ‹‰', 'å®‰æ ¼æ‹‰'],
            'github': ['å‰ç‰¹å“ˆå¸ƒ', 'åŸºç‰¹å“ˆå¸ƒ', 'å‰å“ˆå¸ƒ'],
        }
        
        # æŸ¥æ‰¾å®Œå…¨åŒ¹é…
        if word_lower in phonetic_map:
            variants.extend(phonetic_map[word_lower])
        
        # æŸ¥æ‰¾éƒ¨åˆ†åŒ¹é…
        for key, values in phonetic_map.items():
            if key in word_lower or word_lower in key:
                variants.extend(values)
        
        return variants

# FunASR æ¨¡å‹åˆ—è¡¨
FUNASR_MODELS = [
    "SenseVoiceSmall", "paraformer-zh", "paraformer-zh-streaming", "paraformer-en",
    "conformer-en", "ct-punc", "fsmn-vad", "fsmn-kws", "fa-zh", "cam++",
    "Qwen-Audio", "Qwen-Audio-Chat", "emotion2vec+large"
]

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

# åˆ›å»ºlogger
logger = logging.getLogger("transcribe-audio")
logger.setLevel(logging.WARNING)  # å°†æ—¥å¿—çº§åˆ«ä»INFOæ”¹ä¸ºWARNING

# ç¡®ä¿å…¶ä»–åº“çš„æ—¥å¿—çº§åˆ«ä¸ä¼šå¤ªè¯¦ç»†
logging.getLogger("modelscope").setLevel(logging.ERROR)
logging.getLogger("funasr").setLevel(logging.ERROR)
logging.getLogger("jieba").setLevel(logging.ERROR)
logging.getLogger("werkzeug").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("filelock").setLevel(logging.WARNING)

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB max-limit
app.config['UPLOAD_FOLDER'] = '/app/uploads'


# å…¨å±€æ¨¡å‹å˜é‡
model = None
hotword_processor = None

# å…¨å±€è¿›åº¦è·Ÿè¸ª
current_progress = {
    "status": "idle",
    "progress": 0,
    "total_chunks": 0,
    "current_chunk": 0,
    "message": "ç­‰å¾…å¤„ç†...",
    "start_time": None,
    "estimated_time": None
}

# è®¾ç½®è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆ5åˆ†é’Ÿï¼‰
app.config['TIMEOUT'] = 300

def ensure_dir(dir_path):
    """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    Path(dir_path).mkdir(parents=True, exist_ok=True)

def download_model(model_id, revision, cache_dir):
    """ä¸‹è½½æŒ‡å®šçš„æ¨¡å‹"""
    try:
        logger.info(f"å¼€å§‹ä¸‹è½½æ¨¡å‹ {model_id} åˆ° {cache_dir}")
        
        # ä¸‹è½½æ¨¡å‹
        model_dir = snapshot_download(
            model_id=model_id,
            revision=revision,
            cache_dir=cache_dir
        )
        logger.info(f"æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_dir}")
        
        # ç¡®ä¿ç›®å½•æœ‰å†™æƒé™
        for root, dirs, files in os.walk(cache_dir):
            for d in dirs:
                os.chmod(os.path.join(root, d), 0o755)
            for f in files:
                os.chmod(os.path.join(root, f), 0o644)
        
        return model_dir
    except Exception as e:
        logger.error(f"ä¸‹è½½æ¨¡å‹ {model_id} æ—¶å‡ºé”™: {str(e)}")
        raise

def get_model_id(model_type, model_name):
    """è·å–å®Œæ•´çš„æ¨¡å‹ID"""
    model_mappings = {
        "main": {
            "paraformer-zh": "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "paraformer-zh-streaming": "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "paraformer-en": "damo/speech_paraformer-large_asr_nat-en-16k-common-vocab10020",
            "conformer-en": "damo/speech_conformer_asr_nat-en-16k-common-vocab10020",
            "SenseVoiceSmall": "damo/speech_SenseVoiceSmall_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "fa-zh": "damo/speech_FastConformer_asr_nat-zh-cn-16k-common-vocab8404",
            "Qwen-Audio": "damo/speech_qwen_audio_asr_nat-zh-cn-16k-common-vocab8404",
            "Qwen-Audio-Chat": "damo/speech_qwen_audio_chat_asr_nat-zh-cn-16k-common-vocab8404",
            "emotion2vec+large": "damo/speech_emotion2vec_large_sv_zh-cn_16k-common"
        },
        "vad": {
            "fsmn-vad": "damo/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            "fsmn-kws": "damo/speech_fsmn_kws_zh-cn-16k-common-pytorch"
        },
        "punc": {
            "ct-punc": "damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch"
        },
        "spk": {
            "cam++": "damo/speech_campplus_sv_zh-cn_16k-common"
        }
    }
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„æ¨¡å‹IDï¼ˆåŒ…å«damo/å‰ç¼€ï¼‰
    if model_name.startswith("damo/"):
        return model_name
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ˜ å°„è¡¨ä¸­
    try:
        return model_mappings[model_type][model_name]
    except KeyError:
        # å¦‚æœæ‰¾ä¸åˆ°æ˜ å°„ï¼Œå°è¯•æ„å»ºæ ‡å‡†æ ¼å¼çš„æ¨¡å‹ID
        if model_type == "main":
            # ä¸»æ¨¡å‹IDæ ¼å¼ï¼šdamo/speech_[model_name]_asr_nat-[lang]-16k-common-[vocab]
            if "zh" in model_name.lower():
                return f"damo/speech_{model_name}_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            elif "en" in model_name.lower():
                return f"damo/speech_{model_name}_asr_nat-en-16k-common-vocab10020"
            else:
                return f"damo/speech_{model_name}_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
        elif model_type == "vad":
            # VADæ¨¡å‹IDæ ¼å¼ï¼šdamo/speech_[model_name]_zh-cn-16k-common-pytorch
            return f"damo/speech_{model_name}_zh-cn-16k-common-pytorch"
        elif model_type == "punc":
            # æ ‡ç‚¹æ¨¡å‹IDæ ¼å¼ï¼šdamo/punc_[model_name]_zh-cn-common-vocab272727-pytorch
            return f"damo/punc_{model_name}_zh-cn-common-vocab272727-pytorch"
        elif model_type == "spk":
            # è¯´è¯äººåˆ†ç¦»æ¨¡å‹IDæ ¼å¼ï¼šdamo/speech_[model_name]_sv_zh-cn_16k-common
            return f"damo/speech_{model_name}_sv_zh-cn_16k-common"
        else:
            # å¦‚æœæ— æ³•ç¡®å®šæ ¼å¼ï¼Œç›´æ¥æ·»åŠ damo/å‰ç¼€
            logger.warning(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}ï¼Œå°†ç›´æ¥æ·»åŠ damo/å‰ç¼€")
            return f"damo/{model_name}"

def ensure_models():
    """ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
    # è®¾ç½®æ¨¡å‹ç›®å½•
    model_dir = os.getenv("MODEL_DIR", "/app/models")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['MODELSCOPE_CACHE'] = model_dir
    os.environ['HF_HOME'] = model_dir
    os.environ['TORCH_HOME'] = model_dir
    
    # è·å–æ‰€æœ‰æ¨¡å‹åç§° - ä¼˜å…ˆä½¿ç”¨æ”¯æŒç¬¬ä¸‰ä»£çƒ­è¯çš„æ¨¡å‹
    model_name = os.getenv("FUNASR_MODEL", "SenseVoiceSmall")  # ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹
    vad_model = os.getenv("FUNASR_VAD_MODEL", "fsmn-vad")
    punc_model = os.getenv("FUNASR_PUNC_MODEL", "ct-punc")
    spk_model = os.getenv("FUNASR_SPK_MODEL", "cam++")
    
    # è·å–å®Œæ•´çš„æ¨¡å‹ID
    model_configs = {
        "main": {"name": model_name, "id": get_model_id("main", model_name)},
        "vad": {"name": vad_model, "id": get_model_id("vad", vad_model)},
        "punc": {"name": punc_model, "id": get_model_id("punc", punc_model)},
        "spk": {"name": spk_model, "id": get_model_id("spk", spk_model)}
    }
    
    logger.info("æ£€æŸ¥æ¨¡å‹é…ç½®ï¼š")
    for model_type, config in model_configs.items():
        logger.info(f"{model_type}æ¨¡å‹: {config['name']} (ID: {config['id']})")
    
    # æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    model_paths = {
        model_type: os.path.join(model_dir, f"hub/{config['id']}")
        for model_type, config in model_configs.items()
    }
    
    logger.info("æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ï¼š")
    for model_type, path in model_paths.items():
        logger.info(f"{model_type}æ¨¡å‹è·¯å¾„: {path}")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½æ¨¡å‹
    missing_models = [path for path in model_paths.values() if not os.path.exists(path)]
    if missing_models:
        logger.info("éƒ¨åˆ†æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½...")
        ensure_dir(model_dir)
        
        # ä¸‹è½½æ‰€æœ‰ç¼ºå¤±çš„æ¨¡å‹
        success = True
        for model_type, config in model_configs.items():
            model_path = model_paths[model_type]
            if model_path in missing_models:
                try:
                    downloaded_path = download_model(
                        model_id=config["id"],
                        revision=None,  # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
                        cache_dir=model_dir
                    )
                    logger.info(f"æ¨¡å‹ {config['id']} ä¸‹è½½æˆåŠŸ: {downloaded_path}")
                except Exception as e:
                    logger.error(f"ä¸‹è½½æ¨¡å‹ {config['id']} å¤±è´¥: {str(e)}")
                    success = False
                    continue
        
        if not success:
            logger.error("éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
            sys.exit(1)
        else:
            logger.info(f"æ‰€æœ‰æ¨¡å‹ä¸‹è½½æˆåŠŸï¼Œæ¨¡å‹ç›®å½•: {model_dir}")
    else:
        logger.info("æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— éœ€ä¸‹è½½")
    
    return model_dir, {k: v["name"] for k, v in model_configs.items()}

# åˆå§‹åŒ–FunASRæ¨¡å‹
def init_model():
    global model, hotword_processor  # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
    print("="*50)
    print("å¼€å§‹åˆå§‹åŒ–FunASRæ¨¡å‹...")
    print("æ­£åœ¨æ£€æµ‹GPUçŠ¶æ€...")
    
    try:
        # æ£€æµ‹GPUæ˜¯å¦å¯ç”¨
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print("\n" + "="*20 + " GPUæ£€æµ‹ä¿¡æ¯ " + "="*20)
        print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        if device == "cuda":
            gpu_count = torch.cuda.device_count()
            print(f"å¯ç”¨GPUæ•°é‡: {gpu_count}")
            for i in range(gpu_count):
                print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
                print(f"GPU {i} æ€»å†…å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
                print(f"GPU {i} CUDAç‰ˆæœ¬: {torch.version.cuda}")
                if hasattr(torch.backends.cudnn, 'version'):
                    print(f"GPU {i} cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        else:
            print("è­¦å‘Š: æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPUï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
        
        print("\n" + "="*20 + " æ¨¡å‹åŠ è½½å¼€å§‹ " + "="*20)
        
        # ç¡®ä¿æ¨¡å‹å­˜åœ¨
        model_dir, model_names = ensure_models()
        
        try:
            # å°è¯•ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
            model = AutoModel(
                model=model_names["main"],
                device=device,  # ä½¿ç”¨æ£€æµ‹åˆ°çš„è®¾å¤‡
                model_dir=model_dir,
                vad_model=model_names["vad"],
                vad_kwargs={"max_single_segment_time": 60000},
                punc_model=model_names["punc"],
                spk_model=model_names["spk"],
                batch_size=1 if device == "cpu" else 4,  # GPUæ—¶ä½¿ç”¨æ›´å¤§çš„batch_size
                vad_model_dir=model_dir,
                disable_update=True,
                use_local=True,
                punc_model_dir=model_dir,
                spk_model_dir=model_dir
            )
            print(f"FunASRæ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {device}")
            print(f"ä¸»æ¨¡å‹: {model_names['main']}")
            print(f"VADæ¨¡å‹: {model_names['vad']}")
            print(f"æ ‡ç‚¹æ¨¡å‹: {model_names['punc']}")
            print(f"è¯´è¯äººæ¨¡å‹: {model_names['spk']}")
            print(f"æ‰¹å¤„ç†å¤§å°: {1 if device == 'cpu' else 4}")
            
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½æŒ‡å®šæ¨¡å‹å¤±è´¥: {str(e)}")
            print("å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®")
            
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            model = AutoModel(
                model="paraformer-zh",
                device=device,  # ä½¿ç”¨æ£€æµ‹åˆ°çš„è®¾å¤‡
                model_dir=model_dir,
                vad_model="fsmn-vad",
                vad_kwargs={"max_single_segment_time": 60000},
                punc_model="ct-punc",
                spk_model="cam++",
                batch_size=1 if device == "cpu" else 4,  # GPUæ—¶ä½¿ç”¨æ›´å¤§çš„batch_size
                vad_model_dir=model_dir,
                disable_update=True,
                use_local=True,
                punc_model_dir=model_dir,
                spk_model_dir=model_dir
            )
            print(f"FunASRæ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {device}")
            print(f"ä¸»æ¨¡å‹: paraformer-zh")
            print(f"VADæ¨¡å‹: fsmn-vad")
            print(f"æ ‡ç‚¹æ¨¡å‹: ct-punc")
            print(f"è¯´è¯äººæ¨¡å‹: cam++")
            print(f"æ‰¹å¤„ç†å¤§å°: {1 if device == 'cpu' else 4}")
        
        # éªŒè¯æ¨¡å‹åŠ è½½
        print("éªŒè¯æ¨¡å‹åŠ è½½çŠ¶æ€...")
        test_audio = np.zeros(16000, dtype=np.float32)  # 1ç§’çš„é™éŸ³ç”¨äºæµ‹è¯•
        test_result = model.generate(input=test_audio, sample_rate=16000)
        print(f"æ¨¡å‹éªŒè¯ç»“æœ: {test_result}")
        print("FunASRæ¨¡å‹åŠ è½½å®Œæˆ")
        
        # åˆå§‹åŒ–çƒ­è¯åå¤„ç†å™¨
        print("åˆå§‹åŒ–çƒ­è¯åå¤„ç†å™¨...")
        hotword_processor = HotwordPostProcessor()
        print("çƒ­è¯åå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        return model
        
    except Exception as e:
        print(f"é”™è¯¯: åŠ è½½FunASRæ¨¡å‹å¤±è´¥: {str(e)}")
        import traceback
        print(traceback.format_exc())  # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆ
        sys.exit(1)

# åˆå§‹åŒ–æ¨¡å‹
model = init_model()

@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    device_info = {
        "status": "healthy",
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "gpu_available": torch.cuda.is_available(),
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "gpu_names": [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else [],
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(device_info)

@app.route('/device')
def device_info():
    """è®¾å¤‡ä¿¡æ¯æ¥å£"""
    device_info = {
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "gpu_available": torch.cuda.is_available(),
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "gpu_names": [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())] if torch.cuda.is_available() else [],
        "timestamp": datetime.now().isoformat()
    }
    return jsonify(device_info)

@app.route('/progress')
def get_progress():
    """è·å–å½“å‰è½¬å½•è¿›åº¦"""
    global current_progress
    
    # è®¡ç®—é¢„ä¼°å‰©ä½™æ—¶é—´
    if current_progress["start_time"] and current_progress["current_chunk"] > 0:
        elapsed_time = time.time() - current_progress["start_time"]
        avg_time_per_chunk = elapsed_time / current_progress["current_chunk"]
        remaining_chunks = current_progress["total_chunks"] - current_progress["current_chunk"]
        estimated_remaining = avg_time_per_chunk * remaining_chunks
        current_progress["estimated_time"] = estimated_remaining
    
    return jsonify(current_progress)

def update_progress(status, current_chunk=None, total_chunks=None, message=None):
    """æ›´æ–°è¿›åº¦ä¿¡æ¯"""
    global current_progress
    
    current_progress["status"] = status
    if current_chunk is not None:
        current_progress["current_chunk"] = current_chunk
    if total_chunks is not None:
        current_progress["total_chunks"] = total_chunks
    if message is not None:
        current_progress["message"] = message
    
    if total_chunks and total_chunks > 0:
        current_progress["progress"] = (current_progress["current_chunk"] / total_chunks) * 100
    
    if status == "processing" and current_progress["start_time"] is None:
        current_progress["start_time"] = time.time()
    elif status == "completed" or status == "error":
        current_progress["start_time"] = None
        current_progress["estimated_time"] = None

def convert_audio_to_wav(input_path, target_sample_rate=16000):
    """å°†éŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼å¹¶é‡é‡‡æ ·"""
    try:
        # ä½¿ç”¨pydubåŠ è½½éŸ³é¢‘
        logger.info(f"å¼€å§‹è½¬æ¢éŸ³é¢‘æ–‡ä»¶: {input_path}")
        audio = AudioSegment.from_file(input_path)
        
        logger.info(f"åŸå§‹éŸ³é¢‘ä¿¡æ¯: é€šé“æ•°={audio.channels}, é‡‡æ ·ç‡={audio.frame_rate}Hz, æ—¶é•¿={len(audio)/1000.0}ç§’")
        
        # è½¬æ¢ä¸ºå•å£°é“
        if audio.channels > 1:
            audio = audio.set_channels(1)
            logger.info("å·²è½¬æ¢ä¸ºå•å£°é“")
        
        # è®¾ç½®é‡‡æ ·ç‡
        if audio.frame_rate != target_sample_rate:
            audio = audio.set_frame_rate(target_sample_rate)
            logger.info(f"å·²è°ƒæ•´é‡‡æ ·ç‡è‡³ {target_sample_rate}Hz")
        
        # è°ƒæ•´éŸ³é‡
        if audio.dBFS < -30:  # å¦‚æœéŸ³é‡å¤ªå°
            gain_needed = min(-30 - audio.dBFS, 30)  # æœ€å¤šå¢ç›Š30dB
            audio = audio.apply_gain(gain_needed)
            logger.info(f"éŸ³é‡è¿‡å°ï¼Œå·²å¢åŠ  {gain_needed}dB")
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_wav = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        temp_wav_path = temp_wav.name
        temp_wav.close()
        
        # å¯¼å‡ºä¸ºWAVæ ¼å¼
        audio.export(temp_wav_path, format='wav', parameters=["-ac", "1", "-ar", str(target_sample_rate)])
        logger.info(f"éŸ³é¢‘å·²å¯¼å‡ºä¸ºWAVæ ¼å¼: {temp_wav_path}")
        
        return temp_wav_path
    except Exception as e:
        logger.error(f"éŸ³é¢‘è½¬æ¢å¤±è´¥: {str(e)}")
        raise

def normalize_audio(audio_data):
    """æ ‡å‡†åŒ–éŸ³é¢‘æ•°æ®"""
    try:
        if audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)
        
        # è®¡ç®—éŸ³é¢‘ç»Ÿè®¡ä¿¡æ¯
        mean_val = np.mean(audio_data)
        std_val = np.std(audio_data)
        max_abs = np.max(np.abs(audio_data))
        
        logger.info(f"éŸ³é¢‘ç»Ÿè®¡: å‡å€¼={mean_val:.6f}, æ ‡å‡†å·®={std_val:.6f}, æœ€å¤§ç»å¯¹å€¼={max_abs:.6f}")
        
        # å¦‚æœéŸ³é¢‘å¤ªå¼±ï¼Œè¿›è¡Œæ”¾å¤§
        if max_abs < 0.1:
            scale_factor = 0.5 / max_abs  # æ”¾å¤§åˆ°0.5çš„å¹…åº¦
            audio_data = audio_data * scale_factor
            logger.info(f"éŸ³é¢‘ä¿¡å·è¾ƒå¼±ï¼Œå·²æ”¾å¤§ {scale_factor:.2f} å€")
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨ [-1, 1] èŒƒå›´å†…
        if max_abs > 1.0:
            audio_data = audio_data / max_abs
            logger.info("éŸ³é¢‘æ•°æ®å·²å½’ä¸€åŒ–åˆ° [-1, 1] èŒƒå›´")
        
        # ç§»é™¤DCåç½®
        audio_data = audio_data - np.mean(audio_data)
        
        return audio_data
    except Exception as e:
        logger.error(f"éŸ³é¢‘æ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
        raise

def process_recognition_result(result):
    """å¤„ç†è¯†åˆ«ç»“æœï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œåˆ—è¡¨æ ¼å¼"""
    try:
        logger.debug(f"å¤„ç†è¯†åˆ«ç»“æœ: {type(result)} - {result}")
        
        if isinstance(result, str):
            return result.strip()
        elif isinstance(result, list):
            if len(result) == 0:
                logger.warning("è¯†åˆ«ç»“æœåˆ—è¡¨ä¸ºç©º")
                return ""
            
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå¯èƒ½åŒ…å«å¤šä¸ªè¯†åˆ«ç»“æœæˆ–æ—¶é—´æˆ³ä¿¡æ¯
            text_parts = []
            for i, item in enumerate(result):
                try:
                    if isinstance(item, dict):
                        # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œæå–æ–‡æœ¬éƒ¨åˆ†
                        text = item.get('text', '') or item.get('result', '') or item.get('sentence', '')
                        if text:
                            text_parts.append(text)
                    elif isinstance(item, str):
                        text_parts.append(item)
                    else:
                        logger.debug(f"åˆ—è¡¨é¡¹ {i}: æœªçŸ¥æ ¼å¼ {type(item)} - {item}")
                except Exception as e:
                    logger.warning(f"å¤„ç†åˆ—è¡¨é¡¹ {i} æ—¶å‡ºé”™: {str(e)}")
                    continue
                    
            return ' '.join(filter(None, text_parts)).strip()
        elif isinstance(result, dict):
            # å¤„ç†å­—å…¸æ ¼å¼çš„ç»“æœ
            text = result.get('text', '') or result.get('result', '') or result.get('sentence', '')
            return text.strip() if text else ""
        elif result is None:
            return ""
        else:
            logger.warning(f"æœªçŸ¥çš„è¯†åˆ«ç»“æœæ ¼å¼: {type(result)} - {result}")
            return str(result) if result else ""
    except Exception as e:
        logger.error(f"å¤„ç†è¯†åˆ«ç»“æœæ—¶å‡ºé”™: {str(e)}")
        return ""

def process_audio_chunk(audio_data, sample_rate, chunk_size=30*16000, hotwords=None):
    """åˆ†å—å¤„ç†éŸ³é¢‘æ•°æ®
    
    Args:
        audio_data: éŸ³é¢‘æ•°æ®
        sample_rate: é‡‡æ ·ç‡
        chunk_size: æ¯ä¸ªéŸ³é¢‘å—çš„å¤§å°ï¼ˆé»˜è®¤30ç§’ï¼‰
        hotwords: çƒ­è¯åˆ—è¡¨ï¼Œç”¨äºæé«˜ç‰¹å®šè¯æ±‡çš„è¯†åˆ«å‡†ç¡®ç‡
    """
    try:
        results = []
        total_len = len(audio_data)
        
        # æ ‡å‡†åŒ–éŸ³é¢‘æ•°æ®
        audio_data = normalize_audio(audio_data)
        
        # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œç›´æ¥å¤„ç†æ•´ä¸ªéŸ³é¢‘
        if total_len < chunk_size:
            update_progress("processing", 0, 1, "å¤„ç†çŸ­éŸ³é¢‘...")
            try:
                with torch.no_grad():
                    # print(f"\nå¤„ç†çŸ­éŸ³é¢‘ (é•¿åº¦: {total_len/sample_rate:.2f}ç§’)")
                    # ä¿®å¤çƒ­è¯å‚æ•°ä¼ é€’
                    if hotwords:
                        # FunASRå®˜æ–¹æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨hotwordå‚æ•°ï¼Œç©ºæ ¼åˆ†éš”å¤šä¸ªçƒ­è¯
                        hotword_string = ' '.join(hotwords)
                        logger.warning(f"ğŸ”¥ çŸ­éŸ³é¢‘ä½¿ç”¨çƒ­è¯: '{hotword_string}'")
                        result = model.generate(
                            input=audio_data,
                            hotword=hotword_string
                        )
                    else:
                        logger.warning("ğŸ”¥ çŸ­éŸ³é¢‘è°ƒç”¨ model.generateï¼Œæ— çƒ­è¯")
                        result = model.generate(
                            input=audio_data
                        )
                    processed_result = process_recognition_result(result)
                    
                    # å¯é€‰çš„é¢å¤–çƒ­è¯åå¤„ç†ï¼ˆä½œä¸ºåŸç”Ÿhotwordçš„è¡¥å……ï¼‰
                    if processed_result and hotwords:
                        hotword_result = hotword_processor.process_text_with_hotwords(processed_result, hotwords)
                        processed_result = hotword_result['processed_text']
                        logger.warning(f"ğŸ”¥ çŸ­éŸ³é¢‘é¢å¤–åå¤„ç†ç»“æœ: '{processed_result}' (ä¿®æ­£{hotword_result['corrections']}å¤„)")
                    
                    if processed_result:
                        results.append(processed_result)
                    update_progress("processing", 1, 1, "çŸ­éŸ³é¢‘å¤„ç†å®Œæˆ")
            except Exception as e:
                print(f"å¤„ç†çŸ­éŸ³é¢‘æ—¶å‡ºé”™: {str(e)}")
                update_progress("error", message=f"çŸ­éŸ³é¢‘å¤„ç†é”™è¯¯: {str(e)}")
        else:
            # åˆ†å—å¤„ç†é•¿éŸ³é¢‘
            overlap = int(0.5 * sample_rate)  # 0.5ç§’é‡å 
            total_chunks = (total_len + chunk_size - 1)//chunk_size
            print(f"\nå¼€å§‹å¤„ç†éŸ³é¢‘ï¼Œæ€»å…± {total_chunks} ä¸ªå—")
            update_progress("processing", 0, total_chunks, f"å¼€å§‹å¤„ç† {total_chunks} ä¸ªéŸ³é¢‘å—...")
            
            for i in range(0, total_len, chunk_size - overlap):
                chunk = audio_data[i:min(i+chunk_size, total_len)]
                chunk_num = i//chunk_size + 1
                
                update_progress("processing", chunk_num, total_chunks, f"æ­£åœ¨å¤„ç†ç¬¬ {chunk_num}/{total_chunks} ä¸ªéŸ³é¢‘å—...")
                
                # æ£€æŸ¥éŸ³é¢‘å—çš„æœ‰æ•ˆæ€§
                chunk_max = np.max(np.abs(chunk))
                chunk_energy = np.mean(chunk**2)
                
                # print(f"\nå¤„ç†éŸ³é¢‘å— {chunk_num}/{total_chunks}")
                # print(f"å—ä¿¡æ¯: æœ€å¤§æŒ¯å¹…={chunk_max:.6f}, èƒ½é‡={chunk_energy:.6f}")
                
                # ä½¿ç”¨èƒ½é‡å’ŒæŒ¯å¹…åŒé‡åˆ¤æ–­æ˜¯å¦ä¸ºé™éŸ³
                if chunk_max < 1e-3 or chunk_energy < 1e-6:
                    # print("è·³è¿‡é™éŸ³å—")
                    continue
                
                try:
                    with torch.no_grad():
                        # ä¿®å¤çƒ­è¯å‚æ•°ä¼ é€’
                        if hotwords:
                            # FunASRå®˜æ–¹æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨hotwordå‚æ•°ï¼Œç©ºæ ¼åˆ†éš”å¤šä¸ªçƒ­è¯
                            hotword_string = ' '.join(hotwords)
                            logger.warning(f"ğŸ”¥ é•¿éŸ³é¢‘å—{chunk_num}ä½¿ç”¨çƒ­è¯: '{hotword_string}'")
                            result = model.generate(
                                input=chunk,
                                hotword=hotword_string
                            )
                        else:
                            logger.warning(f"ğŸ”¥ é•¿éŸ³é¢‘å—{chunk_num}è°ƒç”¨ model.generateï¼Œæ— çƒ­è¯")
                            result = model.generate(
                                input=chunk
                            )
                        processed_result = process_recognition_result(result)
                        
                        # å¯é€‰çš„é¢å¤–çƒ­è¯åå¤„ç†ï¼ˆä½œä¸ºåŸç”Ÿhotwordçš„è¡¥å……ï¼‰
                        if processed_result and hotwords:
                            hotword_result = hotword_processor.process_text_with_hotwords(processed_result, hotwords)
                            processed_result = hotword_result['processed_text']
                            logger.warning(f"ğŸ”¥ é•¿éŸ³é¢‘å—{chunk_num}é¢å¤–åå¤„ç†ç»“æœ: '{processed_result}' (ä¿®æ­£{hotword_result['corrections']}å¤„)")
                        
                        if processed_result:
                            results.append(processed_result)
                            # print(f"è¯†åˆ«ç»“æœ: {processed_result}")
                except Exception as e:
                    print(f"å¤„ç†éŸ³é¢‘å— {chunk_num} æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        final_result = " ".join(results)
        print("\néŸ³é¢‘å¤„ç†å®Œæˆï¼")
        update_progress("completed", message="éŸ³é¢‘å¤„ç†å®Œæˆï¼")
        return final_result
        
    except Exception as e:
        print(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
        raise

@app.route('/recognize', methods=['POST'])
def recognize_audio():
    """å¤„ç†éŸ³é¢‘æ–‡ä»¶å¹¶è¿”å›è¯†åˆ«ç»“æœ"""
    temp_files = []  # ç”¨äºè·Ÿè¸ªéœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶
    
    try:
        # åˆå§‹åŒ–è¿›åº¦
        update_progress("starting", 0, 0, "å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶...")
        
        if 'audio' not in request.files:
            update_progress("error", message="æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return jsonify({"error": "æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶"}), 400
            
        audio_file = request.files['audio']
        if not audio_file:
            return jsonify({"error": "ç©ºçš„éŸ³é¢‘æ–‡ä»¶"}), 400
        
        # è·å–åŸå§‹æ–‡ä»¶ä¿¡æ¯
        original_filename = audio_file.filename
        file_size = len(audio_file.read())
        audio_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        logger.info(f"æ¥æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {original_filename}, å¤§å°: {file_size/1024:.2f}KB")
        
        # è·å–çƒ­è¯å‚æ•°
        hotwords_raw = request.form.get('hotwords', '')
        logger.warning(f"ğŸ”¥ FunASRæ¥æ”¶åˆ°åŸå§‹çƒ­è¯å­—ç¬¦ä¸²: '{hotwords_raw}'")
        
        if hotwords_raw:
            hotwords = [word.strip() for word in hotwords_raw.split(',') if word.strip()]
            logger.warning(f"ğŸ”¥ FunASRè§£æåçš„çƒ­è¯åˆ—è¡¨ ({len(hotwords)}ä¸ª): {hotwords}")
        else:
            hotwords = []
            logger.warning("ğŸ”¥ FunASRæ²¡æœ‰æ¥æ”¶åˆ°çƒ­è¯å‚æ•°")
        
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        orig_audio_path = os.path.join(app.config['UPLOAD_FOLDER'], 'temp_audio_orig')
        audio_file.save(orig_audio_path)
        temp_files.append(orig_audio_path)
        
        try:
            # è½¬æ¢éŸ³é¢‘æ ¼å¼
            wav_path = convert_audio_to_wav(orig_audio_path)
            temp_files.append(wav_path)
            
            # è¯»å–è½¬æ¢åçš„éŸ³é¢‘æ–‡ä»¶
            audio_data, sample_rate = sf.read(wav_path)
            
            # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
            if len(audio_data) == 0:
                logger.error("éŸ³é¢‘æ•°æ®ä¸ºç©º")
                return jsonify({"error": "éŸ³é¢‘æ•°æ®ä¸ºç©º"}), 400
                
            if np.all(np.abs(audio_data) < 1e-6):
                logger.error("éŸ³é¢‘æ•°æ®å…¨ä¸ºé™éŸ³")
                return jsonify({"error": "éŸ³é¢‘æ•°æ®å…¨ä¸ºé™éŸ³"}), 400
            
            # åˆ†å—å¤„ç†éŸ³é¢‘
            logger.info("å¼€å§‹éŸ³é¢‘è¯†åˆ«...")
            result = process_audio_chunk(audio_data, sample_rate, hotwords=hotwords if hotwords else None)
            
            # æ”¾å®½å¯¹ç©ºç»“æœçš„å¤„ç†
            if not result or len(result.strip()) == 0:
                logger.warning("è¯†åˆ«ç»“æœä¸ºç©ºï¼Œå°è¯•æ•´ä½“è¯†åˆ«...")
                # å¦‚æœåˆ†å—è¯†åˆ«å¤±è´¥ï¼Œå°è¯•æ•´ä½“è¯†åˆ«
                try:
                    with torch.no_grad():
                        logger.info("å¼€å§‹æ•´ä½“éŸ³é¢‘è¯†åˆ«...")
                        # ä¿®å¤çƒ­è¯å‚æ•°ä¼ é€’
                        if hotwords:
                            # FunASRå®˜æ–¹æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨hotwordå‚æ•°ï¼Œç©ºæ ¼åˆ†éš”å¤šä¸ªçƒ­è¯
                            hotword_string = ' '.join(hotwords)
                            logger.warning(f"æ•´ä½“è¯†åˆ«ä½¿ç”¨çƒ­è¯: '{hotword_string}'")
                            raw_result = model.generate(
                                input=audio_data,
                                hotword=hotword_string
                            )
                        else:
                            logger.warning("æ•´ä½“è¯†åˆ«è°ƒç”¨ model.generateï¼Œæ— çƒ­è¯")
                            raw_result = model.generate(
                                input=audio_data
                            )
                        logger.debug(f"æ•´ä½“è¯†åˆ«åŸå§‹ç»“æœ: {type(raw_result)} - {raw_result}")
                        result = process_recognition_result(raw_result)
                        
                        # å¯é€‰çš„é¢å¤–çƒ­è¯åå¤„ç†ï¼ˆä½œä¸ºåŸç”Ÿhotwordçš„è¡¥å……ï¼‰
                        if result and hotwords:
                            hotword_result = hotword_processor.process_text_with_hotwords(result, hotwords)
                            result = hotword_result['processed_text']
                            logger.warning(f"ğŸ”¥ æ•´ä½“è¯†åˆ«é¢å¤–åå¤„ç†ç»“æœ: '{result}' (ä¿®æ­£{hotword_result['corrections']}å¤„)")
                        
                        logger.info(f"æ•´ä½“è¯†åˆ«å¤„ç†åç»“æœ: {result}")
                except Exception as e:
                    logger.error(f"æ•´ä½“è¯†åˆ«å¤±è´¥: {str(e)}")
                    import traceback
                    logger.error(f"æ•´ä½“è¯†åˆ«é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                    result = ""
            
            logger.info("éŸ³é¢‘è¯†åˆ«å®Œæˆ")
            
            response_data = {
                "success": True,
                "text": result if result and len(result.strip()) > 0 else "",
                "audio_info": {
                    "original_filename": original_filename,
                    "file_size_kb": file_size/1024,
                    "duration_seconds": len(audio_data)/sample_rate,
                    "sample_rate": sample_rate
                }
            }
            return jsonify(response_data)
            
        except Exception as e:
            logger.error(f"å¤„ç†éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return jsonify({"error": f"å¤„ç†éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}), 500
            
    except Exception as e:
        logger.error(f"è¯·æ±‚å¤„ç†å‡ºé”™: {str(e)}")
        return jsonify({"error": f"è¯·æ±‚å¤„ç†å‡ºé”™: {str(e)}"}), 500
        
    finally:
        # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                logger.error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

if __name__ == '__main__':
    try:
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
        
        print("\n" + "="*20 + " FunASRæœåŠ¡å¯åŠ¨ " + "="*20)
        print(f"æœåŠ¡å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç›‘å¬åœ°å€: 0.0.0.0:{10095}")
        print(f"ä¸Šä¼ ç›®å½•: {app.config['UPLOAD_FOLDER']}")
        print(f"æ¨¡å‹ç›®å½•: {os.getenv('MODEL_DIR', '/app/models')}")
        print("="*56 + "\n")
        
        # å¯åŠ¨Flaskåº”ç”¨
        app.run(host='0.0.0.0', port=10095, threaded=True)
    except Exception as e:
        print(f"é”™è¯¯: å¯åŠ¨FunASRæœåŠ¡å¤±è´¥: {str(e)}")
        import traceback
        print(traceback.format_exc())
        sys.exit(1)
